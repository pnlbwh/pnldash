#!/usr/bin/env python
from plumbum import cli, local, FG
import csv
import yaml
from collections import OrderedDict
import sys
from os.path import getmtime
import os
from plumbum.cmd import scp
import pandas as pd
import pnldash_lib.csvs
import pnldash_lib.extra
import pnldash_lib.find
from os.path import exists
from pnldash_config import *
from pnldash_lib import read_project_yml, get_db_dir

TEMPLATE = """\
name: intrust_std
grantId:
description: |
            Meaning of path keys:
            fs:      freesurfer subject directory
            dwied:   eddy corrected DWI
            dwimask: FSL bet generated DWI mask
            etc.
pipelines:
    - parameters:
        version_FreeSurfer: 5.3.0
        hash_UKFTractography: 421a7ad
        hash_tract_querier: e045eab
        hash_BRAINSTools: 41353e8
        hash_trainingDataT1AHCC: d6e5990
      paths:
        fs: _data/003_GNX_007/freesurfer/*/*
        dwied: _data/003_GNX_007/std_dwied0.nrrd
        dwimask: _data/003_GNX_007/std_dwimask0.nrrd
        t1mask: _data/003_GNX_007/std_t1mask0.nrrd
        t1: _data/003_GNX_007/std_t10.nrrd
        wmql: _data/003_GNX_007/wmql/*.vtk
        tractmeasures: _data/003_GNX_007/std_tractmeasures0.csv
        dwixc: _data/003_GNX_007/std_dwixc0.nrrd
        ukf: _data/003_GNX_007/std_ukf0.vtk
        t1xc: _data/003_GNX_007/std_t1xc0.nrrd
        fsindwi: _data/003_GNX_007/std_fsindwi0.nii.gz
        dwi: _data/003_GNX_007/std_dwi0.nhdr
        caseid: 003_GNX_007
        caselist: ./caselist.txt
""".format(local.cwd.name.__str__())


class App(cli.Application):
    def main(self, *args):
        if args:
            print("Unknown command {0!r}".format(args[0]))
            return 1
        if self.nested_command:
            return

@App.subcommand("init")
class Init(cli.Application):
    """Makes template 'pnldash.yml'"""

    force = cli.Flag(['-f', '--force'], default=False, help='force overwrite')

    def main(self):
        if exists(PROJECT_YML) and not self.force:
            msg = "'{}' already exists, to recreate it delete it first or use --force/-f flag.".format(
                PROJECT_YML)
            print(msg)
            sys.exit(1)

        represent_dict_order = lambda self, data: self.represent_mapping('tag:yaml.org,2002:map', data.items())
        yaml.add_representer(OrderedDict, represent_dict_order)

        with open(PROJECT_YML, 'w') as f:
            f.write(TEMPLATE)
        print("Made template '{}'.".format(PROJECT_YML))

@App.subcommand("push")
class Push(cli.Application):
    """Copies pnldash.yml and .pnldash/* to central project database"""

    def main(self):

        centralRepo = get_db_dir()

        destDir = local.path(centralRepo) / local.cwd.__str__().replace(
            '/', '---')[3:]
        destDir.mkdir()

        files = [PROJECT_YML, PATHS_CSV, PARAMS_CSV, EXTRA_CSV, DU_CSV]
        # ymlpath = destDir / read_project_yml()['name'] + '.yml'
        # scp[PROJECT_YML, ymlpath] & FG
        # print("Copied '{}' to '{}'".format(PROJECT_YML, ymlpath))
        for file in files:
            scp[file, destDir] & FG
            print("Copied '{}' to '{}'".format(file, destDir))


def heading(s):
    return s + '\n' + len(s) * '-'


@App.subcommand("status")
class Status(cli.Application):
    """Prints a summary of the project disk usage."""

    cache = cli.Flag(
        ['-c', '--cache'],
        default=False,
        help="Use cached results instead of recomputing them.")

    ls = cli.Flag(
        ['-l', '--ls'],
        default=False,
        help="List extra image files not accounted for by pipelines")

    def main(self):
        pnldash_lib.csvs.make_csvs(useCache=self.cache)

        if not FIND_TXT.exists():
            pnldash_lib.find.Find.invoke()
        else:
            print(
                "'{}' already exists, using that to find unaccounted files (run 'pnldash find' to update it).".format(
                    FIND_TXT.relative_to(local.cwd)))

        print
        pnldash_lib.extra.make_extra(ls=self.ls, useCache=self.cache)
        print

        pd.options.display.float_format = '{:,.2f}'.format

        paths = pd.read_csv(PATHS_CSV)
        extraFiles = pd.read_csv(EXTRA_CSV)
        du = pd.read_csv(DU_CSV)

        from numpy import count_nonzero
        # agg = {'path': 'count', 'sizeMB': 'sum', 'exists': 'sum'}
        # agg = {'sizeMB': {'sizeMB':'sum'},
        #         'exists': {'exists': count_nonzero, 'missing': lambda x: count_nonzero(~x) },
        #        'path': {'total': 'count'}
        #         }
        missing = lambda x: count_nonzero(~x)

        agg = {'sizeMB': ['sum'],
                'exists': [count_nonzero, missing],
                'path': ['count']
                }
        st = paths.groupby(['pipelineId', 'pathKey']).agg(agg)
        st['sizeMB'] = st['sizeMB'] / 1024.0 / 1024.0
        # st.rename(columns={'path':'total'}, inplace=True)
        print(heading('Pipeline Files'))
        # print(st.to_string(index=False))
        print(st.to_string())

        pipelineDiskUsage = paths['sizeMB'].sum() / 1024.0
        print("disk usage (G): {:.2f}".format(pipelineDiskUsage))
        totalDiskUsage = du['diskUsageG'].iloc[0]

        print
        print(heading("Project Directory"))
        print("disk usage (G): {:.2f}".format(totalDiskUsage))


if __name__ == '__main__':
    import pnldash_lib.find
    import pnldash_lib.env
    App.subcommand("find", pnldash_lib.find.Find)
    App.subcommand("env", pnldash_lib.env.Env)
    CACHE_DIR.mkdir()
    App.run()
